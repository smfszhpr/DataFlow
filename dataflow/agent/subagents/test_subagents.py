#!/usr/bin/env python3
"""
æµ‹è¯• Executor å’Œ Debugger SubAgent
"""

import asyncio
import logging
import sys
import os

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dataflow.agent.subagents.executor_subagent import ExecutorSubAgent
from dataflow.agent.subagents.debugger_subagent import DebuggerSubAgent

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

async def test_executor_debugger():
    """
    æµ‹è¯• Executor å’Œ Debugger çš„é…åˆå·¥ä½œ
    """
    
    # LLM é…ç½®ï¼ˆè¿™é‡Œéœ€è¦é…ç½®å®é™…çš„ APIï¼‰
    llm_config = {
        "model": "gpt-3.5-turbo",
        "api_key": "your-api-key-here",  # éœ€è¦é…ç½®å®é™…çš„ API Key
        "api_url": "https://api.openai.com/v1/chat/completions"
    }
    
    # åˆ›å»º SubAgent å®ä¾‹
    executor = ExecutorSubAgent(llm_config=llm_config, sandbox_timeout=30)
    debugger = DebuggerSubAgent(llm_config=llm_config)
    
    # æµ‹è¯•éœ€æ±‚
    test_requirement = "ç”Ÿæˆä¸€ä¸ªä»£ç æ¥ä½¿ç”¨ç‰›é¡¿æ³•æ¥è®¡ç®—æ ¹å·5çš„å‰5ä½æ•°"
    
    print(f"ğŸ¯ æµ‹è¯•éœ€æ±‚: {test_requirement}")
    print("=" * 60)
    
    # ç¬¬ä¸€è½®ï¼šExecutor ç”Ÿæˆå¹¶æ‰§è¡Œä»£ç 
    print("ğŸ“ ç¬¬ä¸€æ­¥ï¼šExecutor ç”Ÿæˆå¹¶æ‰§è¡Œä»£ç ")
    
    executor_input = {
        "requirement": test_requirement,
        "additional_info": "è¯·ç¡®ä¿ä»£ç æœ‰æ¸…æ™°çš„è¾“å‡ºï¼Œæ˜¾ç¤ºè®¡ç®—è¿‡ç¨‹å’Œæœ€ç»ˆç»“æœ"
    }
    
    executor_result = await executor.process(executor_input)
    
    print(f"âœ… Executor æ‰§è¡Œå®Œæˆ")
    print(f"   æˆåŠŸ: {executor_result['success']}")
    print(f"   ä»£ç :\n{executor_result.get('code', 'æ— ')}")
    print(f"   è¾“å‡º: {executor_result.get('stdout', 'æ— ')}")
    
    if executor_result.get('stderr'):
        print(f"   é”™è¯¯è¾“å‡º: {executor_result['stderr']}")
    
    if executor_result.get('error'):
        print(f"   é”™è¯¯ä¿¡æ¯: {executor_result['error']}")
    
    # å¦‚æœéœ€è¦è°ƒè¯•ï¼Œè°ƒç”¨ Debugger
    if executor_result.get('needs_debug', False):
        print("\nğŸ”§ ç¬¬äºŒæ­¥ï¼šDebugger åˆ†æå¹¶ä¿®å¤é”™è¯¯")
        
        debugger_input = {
            "code": executor_result['code'],
            "error": executor_result.get('error', ''),
            "stderr": executor_result.get('stderr', ''),
            "stdout": executor_result.get('stdout', ''),
            "traceback": executor_result.get('execution_result', {}).get('traceback', ''),
            "requirement": test_requirement
        }
        
        debugger_result = await debugger.process(debugger_input)
        
        print(f"âœ… Debugger åˆ†æå®Œæˆ")
        print(f"   æˆåŠŸ: {debugger_result['success']}")
        
        if debugger_result['success']:
            print(f"   ä¿®å¤åçš„ä»£ç :\n{debugger_result.get('fixed_code', 'æ— ')}")
            
            # ç”¨ä¿®å¤åçš„ä»£ç å†æ¬¡æ‰§è¡Œ
            print("\nğŸ”„ ç¬¬ä¸‰æ­¥ï¼šç”¨ä¿®å¤åçš„ä»£ç é‡æ–°æ‰§è¡Œ")
            
            retry_input = {
                "requirement": f"æ‰§è¡Œä¿®å¤åçš„ä»£ç : {test_requirement}",
                "additional_info": "è¿™æ˜¯ç»è¿‡è°ƒè¯•ä¿®å¤çš„ä»£ç "
            }
            
            # ç›´æ¥æ‰§è¡Œä¿®å¤åçš„ä»£ç 
            retry_result = executor.sandbox.execute(
                debugger_result['fixed_code'], 
                "é‡æ–°æ‰§è¡Œä¿®å¤åçš„ä»£ç "
            )
            
            print(f"âœ… é‡æ–°æ‰§è¡Œå®Œæˆ")
            print(f"   æˆåŠŸ: {retry_result['success']}")
            print(f"   è¾“å‡º: {retry_result.get('stdout', 'æ— ')}")
            
            if retry_result.get('stderr'):
                print(f"   é”™è¯¯è¾“å‡º: {retry_result['stderr']}")
        else:
            print(f"   è°ƒè¯•å¤±è´¥: {debugger_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•å®Œæˆï¼")

async def test_simple_case():
    """
    æµ‹è¯•ä¸€ä¸ªç®€å•çš„æˆåŠŸæ¡ˆä¾‹
    """
    # æ¨¡æ‹Ÿ LLM é…ç½®ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰
    llm_config = {
        "model": "test-model",
        "api_key": "test-key",
        "api_url": "test-url"
    }
    
    # åˆ›å»º executorï¼ˆç”¨äºæµ‹è¯•æ²™ç›’åŠŸèƒ½ï¼‰
    executor = ExecutorSubAgent(llm_config=llm_config)
    
    # æµ‹è¯•ä¸€ä¸ªç®€å•çš„ Python ä»£ç 
    test_code = """
import math

def newton_sqrt(n, precision=5):
    '''ä½¿ç”¨ç‰›é¡¿æ³•è®¡ç®—å¹³æ–¹æ ¹'''
    x = n / 2.0  # åˆå§‹çŒœæµ‹
    
    for i in range(20):  # æœ€å¤šè¿­ä»£20æ¬¡
        root = 0.5 * (x + n / x)
        if abs(root - x) < 10**(-precision-1):
            break
        x = root
    
    return round(root, precision)

# è®¡ç®—æ ¹å·5çš„å‰5ä½æ•°
result = newton_sqrt(5, 5)
print(f"ä½¿ç”¨ç‰›é¡¿æ³•è®¡ç®—æ ¹å·5çš„ç»“æœ: {result}")
print(f"éªŒè¯: {result}^2 = {result**2}")
"""
    
    print("ğŸ§ª æµ‹è¯•æ²™ç›’æ‰§è¡ŒåŠŸèƒ½")
    print("=" * 50)
    
    execution_result = executor.sandbox.execute(test_code, "æµ‹è¯•ç‰›é¡¿æ³•è®¡ç®—æ ¹å·5")
    
    print(f"âœ… æ‰§è¡Œç»“æœ:")
    print(f"   æˆåŠŸ: {execution_result['success']}")
    print(f"   è¾“å‡º:\n{execution_result.get('stdout', 'æ— ')}")
    
    if execution_result.get('stderr'):
        print(f"   é”™è¯¯è¾“å‡º: {execution_result['stderr']}")
    
    if execution_result.get('error'):
        print(f"   é”™è¯¯ä¿¡æ¯: {execution_result['error']}")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸš€ å¼€å§‹æµ‹è¯• Executor å’Œ Debugger SubAgent")
    print()
    
    # å…ˆæµ‹è¯•æ²™ç›’åŠŸèƒ½
    print("ğŸ“‹ ç¬¬ä¸€éƒ¨åˆ†ï¼šæµ‹è¯•æ²™ç›’æ‰§è¡Œ")
    asyncio.run(test_simple_case())
    
    print("\n" + "="*60 + "\n")
    
    # ç„¶åæµ‹è¯•å®Œæ•´æµç¨‹ï¼ˆéœ€è¦é…ç½®å®é™…çš„ LLM APIï¼‰
    print("ğŸ“‹ ç¬¬äºŒéƒ¨åˆ†ï¼šæµ‹è¯•å®Œæ•´çš„ Executor + Debugger æµç¨‹")
    print("æ³¨æ„ï¼šéœ€è¦é…ç½®å®é™…çš„ LLM API æ‰èƒ½å®Œæ•´æµ‹è¯•")
    
    # å¦‚æœæœ‰ API é…ç½®ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Šä¸‹é¢è¿™è¡Œ
    # asyncio.run(test_executor_debugger())

if __name__ == "__main__":
    main()
